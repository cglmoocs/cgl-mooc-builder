unit_id,unit_title,lesson_id,lesson_title,lesson_activity,lesson_activity_name,lesson_notes,lesson_video_id,lesson_objectives
1,Course Introduction,1,Course in One Page,,,assets/slides/Lecture_1.pdf,hCJotp2POXM,"<p>Geoffrey gives a short introduction to the course covering it's content and structure. He presents the X-Informatics fields (defined values of X) and the Rallying cry of course: Use Clouds running Data Analytics Collaboratively processing Big Data to solve problems in X-Informatics ( or e-X). The courses is set up as a MOOC divided into units that vary in length but are typically around an hour and those are further subdivided into 5-15 minute lessons. Geoffrey follows discussion of mechanics of course with a list of all the units offered</p>"
1,Course Introduction,2,Overall Introduction,,,assets/slides/Lecture_1.pdf,Oippp8tRbss,"<p>This course gives an overview of big data from a use case (application) point of view noting that big data in field X drives the concept of X-Informatics. It covers applications, algorithms and infrastructure/technology (cloud computing). There are 3 versions of Spring 2014 course: I400 Informatics at IU for Undergraduates, I590 Informatics at IU for Graduate students, I590 component of non residential data science certificate. They differ in homework and recommended/required lectures. A single web resource handles lectures for all 3 classes</p>"
1,Course Introduction,3,Course Topics I,,,assets/slides/Lecture_1.pdf,kIdF8pF7tP8,"<p>Geoffrey discusses some of the available units:<br />Motivation: Big Data and the Cloud; Centerpieces of the Future Economy<br />Introduction: What is Big Data, Data Analytics and X-Informatics<br />Python for Big Data Applications and Analytics: NumPy, SciPy, MatPlotlib<br />Using FutureGrid for Big Data Applications and Analytics Course<br />X-Informatics Physics Use Case, Discovery of Higgs Particle; Counting Events and Basic Statistics Parts I-IV</p>"
1,Course Introduction,4,Course Topics II,,,assets/slides/Lecture_1.pdf,yCgSXOcrBTk,"<p>Geoffrey discusses some more of the available units:X-Informatics Use Cases: Big Data Use Cases Survey<br />Using Plotviz Software for Displaying Point Distributions in 3D<br />X-Informatics Use Case: e-Commerce and Lifestyle with recommender systems<br />Technology Recommender Systems - K-Nearest Neighbors, Clustering and heuristic methods<br />Parallel Computing Overview and familiar examples<br />Cloud Technology  for Big Data Applications & Analytics</p>"
1,Course Introduction,5,Course Topics III,,,assets/slides/Lecture_1.pdf,VO0AP1hGXjQ,"<p>Geoffrey discusses the remainder of the available units:X-Informatics Use Case: Web Search and Text Mining and their technologies<br />Technology for X-Informatics: PageRank<br />Technology for X-Informatics: Kmeans<br />Technology for X-Informatics: MapReduce<br />Technology for X-Informatics: Kmeans and MapReduce Parallelism<br />X-Informatics Use Case: Health<br />X-Informatics Use Case: Sensors<br />X-Informatics Use Case: Radar for Remote Sensing.</p>"
2,Course Motivation: Big Data and Clouds,1,Introduction,,,assets/slides/Lecture_2.pptx,MNZLdidoIiM,"<p>This presents the overview of talk, some trends in computing and data and jobs. Gartner's emerging technology hype cycle shows many areas of Clouds and Big Data. Geoffrey highlights 6 issues of importance: economic imperative, computing model, research model, Opportunities in advancing computing, Opportunities in X-Informatics, Data Science Education</p>"
2,Course Motivation: Big Data and Clouds,2,Data Deluge,,,assets/slides/Lecture_2.pptx,y8NZdvaH-IU,"<p>Geoffrey gives some amazing statistics for total storage; uploaded video and uploaded photos; the social media interactions every minute; aspects of the business big data tidal wave; monitors of aircraft engines; the science research data sizes from particle physics to astronomy and earth science; genes sequenced; and finally the long tail of science. The next slide emphasizes applications using algorithms on clouds. This leads to the rallying cry ''Use Clouds running Data Analytics Collaboratively processing Big Data to solve problems in X-Informatics educated in data science'' with a catalog of the many values of X ''Astronomy, Biology, Biomedicine, Business, Chemistry, Climate, Crisis, Earth Science, Energy, Environment, Finance, Health, Intelligence, Lifestyle, Marketing, Medicine, Pathology, Policy, Radar, Security, Sensor, Social, Sustainability, Wealth and Wellness''</p>"
2,Course Motivation: Big Data and Clouds,3,Jobs,,,assets/slides/Lecture_2.pptx,P84TBNt_kv8,"<p>Jobs abound in clouds and data science. There are documented shortages in data science, computer science and the major tech companies advertise for new talent.</p>"
2,Course Motivation: Big Data and Clouds,4,Industrial Trends,,,assets/slides/Lecture_2.pptx,TdaitkVI7qk,"<p>Trends include the growing importance of mobile devices and comparative decrease in desktop access, the export of internet content, the change in dominant client operating systems, use of social media, thriving chinese internet companies</p>"
2,Course Motivation: Big Data and Clouds,5,Computing Model: Industry adopted clouds which are attractive for data analytics,,,assets/slides/Lecture_2.pptx,TIKWL2tkxAM,"<p>Clouds and Big Data are transformational on a 2-5 year time scale. Already Amazon AWS is a lucrative business with almost a $4B revenue. Geoffrey describes the nature of cloud centers with economies of scale and gives examples of importance of virtualization in server consolidation. Then key characteristics of clouds are reviewed with expected high growth in Infrastructure, Platform and Software as a Service.</p>"
2,Course Motivation: Big Data and Clouds,6,Research Model: 4th Paradigm; From Theory to Data driven science?,,,assets/slides/Lecture_2.pptx,-7hABgDO5Iw,"<p>Geoffrey introduces the 4 paradigms of scientific research with the focus on the new fourth data driven methodology.</p>"
2,Course Motivation: Big Data and Clouds,7,Data Science Process,,,assets/slides/Lecture_2.pptx,Sw2Kmx9XdUc,"<p>Geoffrey introduces the DIKW data to information to knowledge to wisdom paradigm. Data flows through cloud services transforming itself and emerging as new information to input into other transformations.</p>"
2,Course Motivation: Big Data and Clouds,8,Physics-Informatics Looking for Higgs Particle with Large Hadron Collider LHC,,,assets/slides/Lecture_2.pptx,FjmJE2-MqyY,"<p>Geoffrey looks at important particle physics example where the Large hadron Collider has observed the Higgs Boson. He shows this discovery as a bump in a histogram; something that so amazed him 50 years ago that he got a PhD in this field. He left field partly due to the incredible size of author lists on papers</p>"
2,Course Motivation: Big Data and Clouds,9,Recommender Systems I,,,assets/slides/Lecture_2.pptx,IjyxClo4bSE,"<p>Many important applications involve matching users, web pages, jobs, movies, books, events etc. These are all optimization problems with recommender systems one important way of performing this optimization. Geoffrey goes through the example of Netflix -- everything is a recommendation and muses about the power of viewing all sorts of things as items in a bag or more abstractly some space with funny properties</p>"
2,Course Motivation: Big Data and Clouds,10,Recommender Systems II,,,assets/slides/Lecture_2.pptx,_fW9A0kZGW0,"<p>Many important applications involve matching users, web pages, jobs, movies, books, events etc. These are all optimization problems with recommender systems one important way of performing this optimization. Geoffrey goes through the example of Netflix -- everything is a recommendation and muses about the power of viewing all sorts of things as items in a bag or more abstractly some space with funny properties</p>"
2,Course Motivation: Big Data and Clouds,11,Web Search and Information Retrieva,,,assets/slides/Lecture_2.pptx,Nwi7Hxzf6As,"<p>This course also looks at Web Search and here Geoffrey gives an overview of the data analytics for web search, Pagerank as a method of ranking web pages returned and uses material from Yahoo on the subtle algorithms for dynamic personalized choice of material for web pages.</p>"
2,Course Motivation: Big Data and Clouds,12,Cloud Application in Research,,,assets/slides/Lecture_2.pptx,gKf2RgwR6sM,"<p>Geoffrey describes scientific applications and how they map onto clouds, supercomputers, grids and high throughput systems. He likes the cloud use of the Internet of Things and gives examples.</p>"
2,Course Motivation: Big Data and Clouds,13,Parallel Computing and MapReduce,,,assets/slides/Lecture_2.pptx,r-blNidPQCE,"<p>Geoffrey defines MapReduce and gives a homely example from fruit blending.</p>"
2,Course Motivation: Big Data and Clouds,14,Data Science Education,,,assets/slides/Lecture_2.pptx,hX1Y3fmDtdQ,"<p>Geoffrey discusses one reason you are taking this course -- Data Science as an educational initiative and aspects of its Indiana University implementation. Then general; features of online education are discussed with clear growth spearheaded by MOOC's where Geoffrey uses this course and others as an example. He stresses the choice between one class to 100,000 students or 2,000 classes to 50 students and an online library of MOOC lessons. In olden days he suggested ''hermit's cage virtual university'' -- gurus in isolated caves putting together exciting curricula outside the traditional university model. Grading and mentoring models and important online tools are discussed. Clouds have MOOC's describing them and MOOC's are stored in clouds; a pleasing symmetry.</p>"
2,Course Motivation: Big Data and Clouds,15,Conclusions,,,assets/slides/Lecture_2.pptx,Ua0_aaTOpZQ,"<p>The conclusions highlight clouds, data-intensive methodology, employment, data science, MOOC's and never forget the Big Data ecosystem in one sentence ''Use Clouds running Data Analytics Collaboratively processing Big Data to solve problems in X-Informatics educated in data science''</p>"
3,Part I: Data Science generics and Commercial Data Deluge,1,What is X-Informatics and its Motto,,What is X-Informatics and its Motto,assets/slides/Lecture_3.pdf,AKkyWF95Fp4,"<p>This discusses trends that are driven by and accompany Big data. We give some key terms including data, information, knowledge, wisdom, data analytics and data science. WE introduce the motto of the course: Use Clouds running Data Analytics Collaboratively processing Big Data to solve problems in X-Informatics. We list many values of X you can defined in various activities across the world.</p>"
3,Part I: Data Science generics and Commercial Data Deluge,2,Jobs,,Jobs,assets/slides/Lecture_3.pdf,pRlfEigUJAc,<p>Big data is especially important as there are some many related jobs. We illustrate this for both cloud computing and data science from reports by Microsoft and the McKinsey institute respectively. We show a plot from LinkedIn showing rapid increase in the number of data science and analytics jobs as a function of time.</p>
3,Part I: Data Science generics and Commercial Data Deluge,3,Data Deluge -- General Structure,,General Structure,assets/slides/Lecture_3.pdf,mPJ9twAFRQU,<p>We look at some broad features of the data deluge starting with the size of data in various areas especially in science research. We give examples from real world of the importance of big data and illustrate how it is integrated into an enterprise IT architecture. We give some views as to what characterizes Big data and why data science is a science that is needed to interpret all the data.</p>
3,Part I: Data Science generics and Commercial Data Deluge,4,Data Science -- Process,,Data Science Process,assets/slides/Lecture_3.pdf,ydH34L-z0Rk,"<p>We stress the DIKW pipeline: Data becomes information that becomes knowledge and then wisdom, policy and decisions. This pipeline is illustrated with Google maps and we show how complex the ecosystem of data, transformations (filters) and its derived forms is.</p>"
3,Part I: Data Science generics and Commercial Data Deluge,5,Data Deluge -- Internet,,Internet,assets/slides/Lecture_3.pdf,rtuq5y2Bx2g,"<p>We give examples of Big data from the Internet with Tweets, uploaded photos and an illustration of the vitality  and size of many commodity applications.</p>"
3,Part I: Data Science generics and Commercial Data Deluge,6,Data Deluge -- Business I,,,assets/slides/Lecture_3.pdf,PJz38t6yn_s,"<p>We give examples including the Big data that enables wind farms, city transportation, telephone operations, machines with health monitors, the banking,  manufacturing and retail industries both online and offline in shopping malls. We give examples from ebay showing how analytics allowing them to refine and improve the customer experiences.</p>"
3,Part I: Data Science generics and Commercial Data Deluge,7,Data Deluge -- Business II,,,assets/slides/Lecture_3.pdf,fESm-2Vox9M,"<p>We give examples including the Big data that enables wind farms, city transportation, telephone operations, machines with health monitors, the banking,  manufacturing and retail industries both online and offline in shopping malls. We give examples from ebay showing how analytics allowing them to refine and improve the customer experiences.</p>"
3,Part I: Data Science generics and Commercial Data Deluge,8,Data Deluge -- Business III,,,assets/slides/Lecture_3.pdf,fcvn-IxPO00,"<p>We give examples including the Big data that enables wind farms, city transportation, telephone operations, machines with health monitors, the banking,  manufacturing and retail industries both online and offline in shopping malls. We give examples from ebay showing how analytics allowing them to refine and improve the customer experiences.</p>"
4,Part II: Data Deluge and Scientific Applications and Methodology,1,Science & Research I,,Science & Research I,assets/slides/Lecture_4.pdf,u1h6bAkuWQ8,"<p>We look into more big data examples with a focus on science and research. We give astronomy, genomics, radiology, particle physics and discovery of Higgs particle (Covered in more detail in later lessons), European Bioinformatics Institute and contrast to Facebook and Walmart</p>"
4,Part II: Data Deluge and Scientific Applications and Methodology,2,Science & Research II,,Science & Research II,assets/slides/Lecture_4.pdf,_JfcUg2cheg,"<p>We look into more big data examples with a focus on science and research. We give astronomy, genomics, radiology, particle physics and discovery of Higgs particle (Covered in more detail in later lessons), European Bioinformatics Institute and contrast to Facebook and Walmart</p>"
4,Part II: Data Deluge and Scientific Applications and Methodology,3,Implications for Scientific Method,,Implications for Scientific Method,assets/slides/Lecture_4.pdf,srEbOAmU_g8,<p>We discuss the emergences of a new fourth methodology for scientific research based on data driven inquiry. We contrast this with third -- computation or simulation based discovery - methodology which emerged itself some 25 years ago.</p>
4,Part II: Data Deluge and Scientific Applications and Methodology,4,Long Tail of Science,,Long Tail of Science,assets/slides/Lecture_4.pdf,dwzEKEGYhqE,<p>There is big science such as particle physics where a single experiment has 3000 people collaborate!.Then there are individual investigators who don't generate a lot of data each but together they add up to Big data.</p>
4,Part II: Data Deluge and Scientific Applications and Methodology,5,Internet of Things,,Internet of Things,assets/slides/Lecture_4.pdf,K2anbyxX48w,"<p>A final category of Big data comes from the Internet of Things where lots of small devices -- smart phones, web cams, video games collect and disseminate data and are controlled and coordinated in the cloud</p>"
5,Part III: Clouds and Big Data Processing; Data Science Process and Analytics,1,Clouds,,Clouds,assets/slides/Lecture_5.pdf,8RBzooC_2Fw,"<p>We describe cloud data centers with their staggering size with up to a million servers in a single data center and centers built modularly from shipping containers full of racks. The benefits of Clouds in terms of power consumption and the environment are also touched upon, followed by a list of the most critical features of Cloud computing and a comparison to supercomputing.</p>"
5,Part III: Clouds and Big Data Processing; Data Science Process and Analytics,2,Features of Data Deluge I,,Features of Data Deluge I,assets/slides/Lecture_5.pdf,FMktnTQGyrw,"<p>Data, Information, intelligence algorithms, infrastructure, data structure, semantics and knowledge are related. The semantic web and Big data are compared. We give an example where ''More data usually beats better algorithms''. We discuss examples of intelligent big data and list 8 different types of data deluge</p>"
5,Part III: Clouds and Big Data Processing; Data Science Process and Analytics,3,Features of Data Deluge II,,Features of Data Deluge II,assets/slides/Lecture_5.pdf,QNVZobXHiZw,"<p>Data, Information, intelligence algorithms, infrastructure, data structure, semantics and knowledge are related. The semantic web and Big data are compared. We give an example where ''More data usually beats better algorithms''. We discuss examples of intelligent big data and list 8 different types of data deluge</p>"
5,Part III: Clouds and Big Data Processing; Data Science Process and Analytics,4,Data Science Process,,Data Science Process,assets/slides/Lecture_5.pdf,lpQ-Q9ZidR4,<p>We describe and critique one view of the work of a data scientists. Then we discuss and contrast 7 views of the process needed to speed data through the DIKW pipeline.</p>
5,Part III: Clouds and Big Data Processing; Data Science Process and Analytics,5,Data Analytics I,,,assets/slides/Lecture_5.pdf,RPVojR8jrb8,<p>We stress the importance of data analytics giving examples from several fields. We note that better analytics is as important as better computing and storage capability.</p>
5,Part III: Clouds and Big Data Processing; Data Science Process and Analytics,6,Data Analytics II,,,assets/slides/Lecture_5.pdf,wOSgywqdJDY,<p>We stress the importance of data analytics giving examples from several fields. We note that better analytics is as important as better computing and storage capability.</p>
6,"Python for Big Data and X-Informatics: NumPy, SciPy, MatPlotlib",1,Introduction,,,assets/slides/Lecture_6.pdf,Gh0WWPJbuJc,"<p>This section is meant to give an overview of the python tools needed for doing for this course. These are really powerful tools which every data scientist who wishes to use python must know. This section covers Canopy, NumPy, MatPlotLib, and Scipy.</p>"
6,"Python for Big Data and X-Informatics: NumPy, SciPy, MatPlotlib",2,Canopy,,,assets/slides/Lecture_6.pdf,x7IQL5YvDwk,<p>Canopy - Its is an IDE for python developed by EnThoughts. The aim of this IDE is to bring the various python libraries under one single framework or ''Canopy'' - that is why the name.</p>
6,"Python for Big Data and X-Informatics: NumPy, SciPy, MatPlotlib",3,Numpy 1,,,assets/slides/Lecture_6.pdf,mN_JpGO9Y6s,"<p>NumPy - It is popular library on top of which many other libraries (like pandas, scipy) are built. It provides a way a vectorizing data. This helps to organize in a more intuitive fashion and also helps us use the various matrix operations which are popularly used by the machine learning community.</p>"
6,"Python for Big Data and X-Informatics: NumPy, SciPy, MatPlotlib",4,Numpy 2,,,assets/slides/Lecture_6.pdf,7QfW7AT7UNU,"<p>NumPy - It is popular library on top of which many other libraries (like pandas, scipy) are built. It provides a way a vectorizing data. This helps to organize in a more intuitive fashion and also helps us use the various matrix operations which are popularly used by the machine learning community.</p>"
6,"Python for Big Data and X-Informatics: NumPy, SciPy, MatPlotlib",5,Numpy 3,,,assets/slides/Lecture_6.pdf,Ccb67Q5gpsk,"<p>NumPy - It is popular library on top of which many other libraries (like pandas, scipy) are built. It provides a way a vectorizing data. This helps to organize in a more intuitive fashion and also helps us use the various matrix operations which are popularly used by the machine learning community.</p>"
6,"Python for Big Data and X-Informatics: NumPy, SciPy, MatPlotlib",6,Matplotlib 1,,,assets/slides/Lecture_6.pdf,3UOvB5OmtYE,"<p>Matplotlib: This a data visualization package. It allows you to create graphs charts and other such diagrams. It supports Images in JPEG, GIF, TIFF format.</p>"
6,"Python for Big Data and X-Informatics: NumPy, SciPy, MatPlotlib",7,Matplotlib 2,,,assets/slides/Lecture_6.pdf,9ONSnsN4hcg,"<p>Matplotlib: This a data visualization package. It allows you to create graphs charts and other such diagrams. It supports Images in JPEG, GIF, TIFF format.</p>"
6,"Python for Big Data and X-Informatics: NumPy, SciPy, MatPlotlib",8,Scipy 1,,,assets/slides/Lecture_6.pdf,lpC6Mn-09jY,"<p>SciPy: SciPy is a library built above numpy and has a number of off the shelf algorithms / operations implemented. These include algorithms from calculus(like integration), statistics, linear algebra, image-processing, signal processing, machine learning, etc.</p>"
6,"Python for Big Data and X-Informatics: NumPy, SciPy, MatPlotlib",9,Scipy 2,,,assets/slides/Lecture_6.pdf,-XKBz7qCUqw,"<p>SciPy: SciPy is a library built above numpy and has a number of off the shelf algorithms / operations implemented. These include algorithms from calculus(like integration), statistics, linear algebra, image-processing, signal processing, machine learning, etc.</p>"
7,Using FutureGrid for Java and Python,1,FutureGrid Overview,,,assets/slides/Lecture_7.pdf,RibpNSyd4qg,<p>In this video Geoffrey introduces Future Grid in terms of its services and features</p>
7,Using FutureGrid for Java and Python,2,Create FG Portal Account,,,assets/slides/Lecture_7.pdf,c7mjKI8mJws,"<p>This lesson explains how to create a portal account, which is the first step in gaining access to FutureGrid</p>"
7,Using FutureGrid for Java and Python,3,Upload an OpenId,,,assets/slides/Lecture_7.pdf,rZzpCYWDEpI,<p>This lesson explains how to upload and use OpenID to easily log into the FutureGrid portal.</p>
7,Using FutureGrid for Java and Python,4,Upload SSH Key,,,assets/slides/Lecture_7.pdf,4wjVwQbOlSU,<p>This lesson explains how to upload and use a SSH key to log to the FutureGrid resources</p>
7,Using FutureGrid for Java and Python,5,Joining the FG project,,,assets/slides/Lecture_7.pdf,aO5B_OQrQ5Q,<p>This lesson explains how to join a FutureGrid project</p>
7,Using FutureGrid for Java and Python,6,Logging into FG,,,assets/slides/Lecture_7.pdf,pI_oHBijrAc,<p>This lesson explains how to log into FG and our customized shell and menu options that will simplify management of the VMs for this upcoming lessons.</p>
7,Using FutureGrid for Java and Python,7,VM Management,,,assets/slides/Lecture_7.pdf,YyJpBmqocYU,"<p>This lesson is about VM management and explains how to start the VM, login to it etc.</p>"
7,Using FutureGrid for Java and Python,8,Accessing IPython and running Python examples,,,assets/slides/Lecture_7.pdf,V9WDTQQxGr8,<p>This lesson talks about IPython and how to create and execute python programs.</p>
7,Using FutureGrid for Java and Python,9,Running Java and Python on FG,,,assets/slides/Lecture_7.pdf,ecFW6AafMuQ,<p>This lesson explains about Running Java and Python on FG</p>
8,"I: Looking for Higgs Particles, Bumps in Histograms, Experiments and Accelerators",1,Looking for Higgs Particle and Counting Introduction I,,,assets/slides/Lecture_8.pptx,VQAupoFUWTg,<p>We return to particle case with slides used in introduction and stress that particles often manifested as bumps in histograms and those bumps need to be large enough to stand out from background in a statistically significant fashion.</p>
8,"I: Looking for Higgs Particles, Bumps in Histograms, Experiments and Accelerators",2,Looking for Higgs Particle and Counting Introduction II,,,assets/slides/Lecture_8.pptx,UAMzmOgjj7I,<p>We give a few details on one LHC experiment ATLAS. Experimental physics papers have a staggering number of authors and quite big budgets. Feynman diagrams describe processes in a fundamental fashion.</p>
8,"I: Looking for Higgs Particles, Bumps in Histograms, Experiments and Accelerators",3,Physics-Informatics Looking for Higgs Particle Experiments,,,assets/slides/Lecture_8.pptx,BW12d780qT8,<p>We give a few details on one LHC experiment ATLAS. Experimental physics papers have a staggering number of authors and quite big budgets. Feynman diagrams describe processes in a fundamental fashion.</p>
8,"I: Looking for Higgs Particles, Bumps in Histograms, Experiments and Accelerators",4,Accelerator Picture Gallery of Big Science,,,assets/slides/Lecture_8.pptx,WLJIxWWMYi8,"<p>This lesson gives a small picture gallery of accelerators. Accelerators, detection chambers and magnets in tunnels and a large underground laboratory used fpr experiments where you need to be shielded from background like cosmic rays</p>"
9,II: Looking for Higgs Particles: Python Event Counting for Signal and Background,1,Physics Use Case II 1: Class Software,,,assets/slides/Lecture_9.pptx,tOFJEUM-Vww,<p>We discuss how this unit uses Java and Python on both a backend server (FutureGrid) or a local client. WE point out useful book on Python for data analysis. This builds on technology training in Section 3</p>
9,II: Looking for Higgs Particles: Python Event Counting for Signal and Background,2,Physics Use Case II 2: Event Counting,,,assets/slides/Lecture_9.pptx,h8-szCeFugQ,<p>We define ''event counting'' data collection environments. We discuss the python and Java code to generate events according to a particular scenario (the important idea of Monte Carlo data). Here a sloping background plus either a Higgs particle generated similarly to LHC observation or one observed with better resolution (smaller measurement error).</p>
9,II: Looking for Higgs Particles: Python Event Counting for Signal and Background,3,Physics Use Case II 3: With Python examples of Signal plus Background,,,assets/slides/Lecture_9.pptx,bl2f0tAzLj4,<p>This uses Monte Carlo data both to generate data like the experimental observations and explore effect of changing amount of data and changing measurement resolution for Higgs.</p>
9,II: Looking for Higgs Particles: Python Event Counting for Signal and Background,4,Physics Use Case II 4: Change shape of background & num of Higgs Particles,,,assets/slides/Lecture_9.pptx,bw3fd5cfQhk,<p>This lesson continues the examination of Monte Carlo data looking at effect of change in number of Higgs particles produced and in change in shape of background</p>
10,"III: Looking for Higgs Particles: Random Variables, Physics and Normal Distributions",1,Statistics Overview and Fundamental Idea: Random Variables,,Random Variables,assets/slides/Lecture_10.pptx,0oZzALLzYBM,<p>We go through the many different areas of statistics covered in the Physics unit. We define the statistics concept of a random variable.</p>
10,"III: Looking for Higgs Particles: Random Variables, Physics and Normal Distributions",2,Physics and Random Variables I,,Physics and Random Variables,assets/slides/Lecture_10.pptx,Tn3GBxgplxg,<p>We describe the DIKW pipeline for the analysis of this type of physics experiment and go through details of analysis pipeline for the LHC ATLAS experiment. We give examples of event displays showing the final state particles seen in a few events. We illustrate how physicists decide whats going on with a plot of expected Higgs production experimental cross sections (probabilities) for signal and background.</p>
10,"III: Looking for Higgs Particles: Random Variables, Physics and Normal Distributions",3,Physics and Random Variables II,,Physics and Random Variables,assets/slides/Lecture_10.pptx,qWEjp0OtvdA,<p>We describe the DIKW pipeline for the analysis of this type of physics experiment and go through details of analysis pipeline for the LHC ATLAS experiment. We give examples of event displays showing the final state particles seen in a few events. We illustrate how physicists decide whats going on with a plot of expected Higgs production experimental cross sections (probabilities) for signal and background.</p>
10,"III: Looking for Higgs Particles: Random Variables, Physics and Normal Distributions",4,Statistics of Events with Normal Distributions,,Statistics of Events with Normal Distributions I,assets/slides/Lecture_10.pptx,LMBtpWOOQLo,<p>We introduce Poisson and Binomial distributions and define independent identically distributed (IID) random variables. We give the law of large numbers defining the errors in counting and leading to Gaussian distributions for many things. We demonstrate this in Python experiments.</p>
10,"III: Looking for Higgs Particles: Random Variables, Physics and Normal Distributions",5,Gaussian Distributions,,Statistics of Events with Normal Distributions II,assets/slides/Lecture_10.pptx,LWIbPa-P5W0,<p>We introduce the Gaussian distribution and give Python examples of the fluctuations in counting Gaussian distributions.</p>
10,"III: Looking for Higgs Particles: Random Variables, Physics and Normal Distributions",6,Using Statistics,,,assets/slides/Lecture_10.pptx,n4jlUrGwgic,<p>We discuss the significance of a standard deviation and role of biases and insufficient statistics with a Python example in getting incorrect answers.</p>
11,"IV: Looking for Higgs Particles: Random Numbers, Distributions and Central Limit Theorem",1,Generators and Seeds I,,,assets/slides/Lecture_11.pptx,76jbRphjRWo,<p>We define random numbers and describe how to generate them on the computer giving Python examples. We define the seed used to define to specify how to start generation.</p>
11,"IV: Looking for Higgs Particles: Random Numbers, Distributions and Central Limit Theorem",2,Generators and Seeds II,,,assets/slides/Lecture_11.pptx,9QY5qkQj2Ag,<p>We define random numbers and describe how to generate them on the computer giving Python examples. We define the seed used to define to specify how to start generation.</p>
11,"IV: Looking for Higgs Particles: Random Numbers, Distributions and Central Limit Theorem",3,Binomial Distribution,,,assets/slides/Lecture_11.pptx,DPd-eVI_twQ,<p>We define binomial distribution and give LHC data as an eaxmple of where this distribution valid.</p>
11,"IV: Looking for Higgs Particles: Random Numbers, Distributions and Central Limit Theorem",4,Accept-Reject,,,assets/slides/Lecture_11.pptx,GfshkKMKCj8,<p>We introduce an advanced method -- accept/reject -- for generating random variables with arbitrary distrubitions.</p>
11,"IV: Looking for Higgs Particles: Random Numbers, Distributions and Central Limit Theorem",5,Monte Carlo Method,,,assets/slides/Lecture_11.pptx,kIQ-BTyDfOQ,<p>We define Monte Carlo method which usually uses accept/reject method in typical case for distribution.</p>
11,"IV: Looking for Higgs Particles: Random Numbers, Distributions and Central Limit Theorem",6,Poisson Distribution,,,assets/slides/Lecture_11.pptx,WFvgsVo-k4s,<p>We extend the Binomial to the Poisson distribution and give a set of amusing examples from Wikipedia.</p>
11,"IV: Looking for Higgs Particles: Random Numbers, Distributions and Central Limit Theorem",7,Central Limit Theorem,,,assets/slides/Lecture_11.pptx,ZO53iKlPn7c,<p>We introduce Central Limit Theorem and give examples from Wikipedia.</p>
11,"IV: Looking for Higgs Particles: Random Numbers, Distributions and Central Limit Theorem",8,Interpretation of Probability: Bayes v. Frequency,,,assets/slides/Lecture_11.pptx,jzDkExAQI9M,<p>This lesson describes difference between Bayes and frequency views of probability. Bayes's law of conditional probability is derived and applied to Higgs example to enable information about Higgs from multiple channels and multiple experiments to be accumulated.</p>
12,Overview of NIST Big Data Public Working Group (NBD-PWG) Process and Results,1,Introduction to NIST Big Data Public Working Group (NBD-PWG) Process,,,assets/slides/Lecture_12.pptx,ofRfHBKpyvg,"<p>The focus of the (NBD-PWG) is to form a community of interest from industry, academia, and government, with the goal of developing a consensus definitions, taxonomies, secure reference architectures, and technology roadmap.  The aim is to create vendor-neutral, technology and infrastructure agnostic deliverables to enable big data stakeholders to pick-and-choose best analytics tools for their processing and visualization requirements on the most suitable computing platforms and clusters while allowing value-added from big data service providers and flow of data between the stakeholders in a cohesive and secure manner.</p>"
12,Overview of NIST Big Data Public Working Group (NBD-PWG) Process and Results,2,Definitions and Taxonomies Subgroup,,,assets/slides/Lecture_12.pptx,sGshHN-DdbE,"<p>The focus is to gain a better understanding of the principles of Big Data. It is important to develop a consensus-based common language and vocabulary terms used in Big Data across stakeholders from industry, academia, and government.  In addition, it is also critical to identify essential actors with roles and responsibility, and subdivide them into components and sub-components on how they interact/ relate with each other according to their similarities and differences.</p><p>For Definitions: Compile terms used from all stakeholders regarding the meaning of Big Data from various standard bodies, domain applications, and diversified operational environments. For Taxonomies: Identify key actors with their roles and responsibilities from all stakeholders, categorize them into components and subcomponents based on their similarities and differences. In particular data Science and Big Data terms are discussed</p>"
12,Overview of NIST Big Data Public Working Group (NBD-PWG) Process and Results,3,Reference Architecture Subgroup,,,assets/slides/Lecture_12.pptx,JV596ZH36YA,"<p>The focus is to form a community of interest from industry, academia, and government, with the goal of developing a consensus-based approach to orchestrate vendor-neutral, technology and infrastructure agnostic for analytics tools and computing environments. The goal is to enable Big Data stakeholders to pick-and-choose technology-agnostic analytics tools for processing and visualization in any computing platform and cluster while allowing value-added from Big Data service providers and  the flow of the data between the stakeholders in a cohesive and secure manner. Results include a reference architecture with well defined components and linkage as well as several exemplars</p>"
12,Overview of NIST Big Data Public Working Group (NBD-PWG) Process and Results,4,Security and Privacy Subgroup,,,assets/slides/Lecture_12.pptx,Gbk0LaWE3lM,"<p>The focus is to form a community of interest from industry, academia, and government, with the goal of developing a consensus secure reference architecture to handle security and privacy issues across all stakeholders.  This includes gaining an understanding of what standards are available or under development, as well as identifies which key organizations are working on these standards. The Top Ten Big Data Security and Privacy Challenges from the CSA (Cloud Security Alliance) BDWG are studied. Specialized use cases include Retail/Marketing, Modern Day Consumerism, Nielsen Homescan, Web Traffic Analysis, Healthcare, Health Information Exchange, Genetic Privacy, Pharma Clinical Trial Data Sharing, Cyber-security, Government, Military and Education.</p>"
12,Overview of NIST Big Data Public Working Group (NBD-PWG) Process and Results,5,Technology Roadmap Subgroup,,,assets/slides/Lecture_12.pptx,GCc9yfErmd0,"<p>The focus is to form a community of interest from industry, academia, and government, with the goal of developing a consensus vision with recommendations on how Big Data should move forward by performing a good gap analysis through the materials gathered from all other NBD subgroups. This includes setting standardization and adoption priorities through an understanding of what standards are available or under development as part of the recommendations. Tasks are gather input from NBD subgroups and study the taxonomies for the actors' roles and responsibility, use cases and requirements, and secure reference architecture; gain understanding of what standards are available or under development for Big Data; perform a thorough gap analysis and document the findings; identify what possible barriers may delay or prevent adoption of Big Data; and document vision and recommendations.</p>"
12,Overview of NIST Big Data Public Working Group (NBD-PWG) Process and Results,6,Requirements and Use Case Subgroup Introduction I,,,assets/slides/Lecture_12.pptx,sztqNXJ9P6c,"<p>The focus is to form a community of interest from industry, academia, and government, with the goal of developing a consensus list of Big Data requirements across all stakeholders.  This includes gathering and understanding various use cases from diversified application domains.Tasks are gather use case input from all stakeholders; derive Big Data requirements from each use case; analyze/prioritize a list of challenging general requirements that may delay or prevent adoption of Big Data deployment; develop a set of general patterns capturing the ''essence'' of use cases (not done yet) and work with Reference Architecture to validate requirements and reference architecture by explicitly implementing some patterns based on use cases. The progress of gathering use cases (discussed in next two units) and requirements systemization are discussed.</p>"
12,Overview of NIST Big Data Public Working Group (NBD-PWG) Process and Results,7,Requirements and Use Case Subgroup Introduction II,,,assets/slides/Lecture_12.pptx,0sbfIqHUauI,"<p>The focus is to form a community of interest from industry, academia, and government, with the goal of developing a consensus list of Big Data requirements across all stakeholders.  This includes gathering and understanding various use cases from diversified application domains.Tasks are gather use case input from all stakeholders; derive Big Data requirements from each use case; analyze/prioritize a list of challenging general requirements that may delay or prevent adoption of Big Data deployment; develop a set of general patterns capturing the ''essence'' of use cases (not done yet) and work with Reference Architecture to validate requirements and reference architecture by explicitly implementing some patterns based on use cases. The progress of gathering use cases (discussed in next two units) and requirements systemization are discussed.</p>"
12,Overview of NIST Big Data Public Working Group (NBD-PWG) Process and Results,8,Requirements and Use Case Subgroup Introduction III,,,assets/slides/Lecture_12.pptx,u59559nqjiY,"<p>The focus is to form a community of interest from industry, academia, and government, with the goal of developing a consensus list of Big Data requirements across all stakeholders.  This includes gathering and understanding various use cases from diversified application domains.Tasks are gather use case input from all stakeholders; derive Big Data requirements from each use case; analyze/prioritize a list of challenging general requirements that may delay or prevent adoption of Big Data deployment; develop a set of general patterns capturing the ''essence'' of use cases (not done yet) and work with Reference Architecture to validate requirements and reference architecture by explicitly implementing some patterns based on use cases. The progress of gathering use cases (discussed in next two units) and requirements systemization are discussed.</p>"
13,51 Big Data Use Cases,1,Government Use Cases I,,,assets/slides/Lecture_13.pptx,gCqBFYDDzSQ,"<p>This covers Census 2010 and 2000 - Title 13 Big Data; National Archives and Records Administration Accession NARA, Search, Retrieve, Preservation; Statistical Survey Response Improvement (Adaptive Design) and Non-Traditional Data in Statistical Survey Response Improvement (Adaptive Design).</p>"
13,51 Big Data Use Cases,2,Government Use Cases II,,,assets/slides/Lecture_13.pptx,y0nIed-Nxjw,"<p>This covers Census 2010 and 2000 - Title 13 Big Data; National Archives and Records Administration Accession NARA, Search, Retrieve, Preservation; Statistical Survey Response Improvement (Adaptive Design) and Non-Traditional Data in Statistical Survey Response Improvement (Adaptive Design).</p>"
13,51 Big Data Use Cases,3,Commercial Use Cases I,,,assets/slides/Lecture_13.pptx,P1iuViI-AKc,"<p>This covers Cloud Eco-System, for Financial Industries (Banking, Securities & Investments, Insurance) transacting business within the United States; Mendeley - An International Network of Research; Netflix Movie Service; Web Search; IaaS (Infrastructure as a Service) Big Data Business Continuity & Disaster Recovery (BC/DR) Within A Cloud Eco-System; Cargo Shipping; Materials Data for Manufacturing and Simulation driven Materials Genomics.</p>"
13,51 Big Data Use Cases,4,Commercial Use Cases II,,,assets/slides/Lecture_13.pptx,epFH4w_Q9lc,"<p>This covers Cloud Eco-System, for Financial Industries (Banking, Securities & Investments, Insurance) transacting business within the United States; Mendeley - An International Network of Research; Netflix Movie Service; Web Search; IaaS (Infrastructure as a Service) Big Data Business Continuity & Disaster Recovery (BC/DR) Within A Cloud Eco-System; Cargo Shipping; Materials Data for Manufacturing and Simulation driven Materials Genomics.</p>"
13,51 Big Data Use Cases,5,Commercial Use Cases III,,,assets/slides/Lecture_13.pptx,j5kWjL4y7Bo,"<p>This covers Cloud Eco-System, for Financial Industries (Banking, Securities & Investments, Insurance) transacting business within the United States; Mendeley - An International Network of Research; Netflix Movie Service; Web Search; IaaS (Infrastructure as a Service) Big Data Business Continuity & Disaster Recovery (BC/DR) Within A Cloud Eco-System; Cargo Shipping; Materials Data for Manufacturing and Simulation driven Materials Genomics.</p>"
13,51 Big Data Use Cases,6,Defense Use Cases I,,,assets/slides/Lecture_13.pptx,8hXG7dinhjg,<p>This covers Large Scale Geospatial Analysis and Visualization; Object identification and tracking from Wide Area Large Format Imagery (WALF) Imagery or Full Motion Video (FMV) - Persistent Surveillance and Intelligence Data Processing and Analysis.</p>
13,51 Big Data Use Cases,7,Defense Use Cases II,,,assets/slides/Lecture_13.pptx,MplyAfmuxko,<p>This covers Large Scale Geospatial Analysis and Visualization; Object identification and tracking from Wide Area Large Format Imagery (WALF) Imagery or Full Motion Video (FMV) - Persistent Surveillance and Intelligence Data Processing and Analysis.</p>
13,51 Big Data Use Cases,8,Healthcare and Life Science Use Cases I,,,assets/slides/Lecture_13.pptx,jVARCWVeYxQ,"<p>This covers Electronic Medical Record (EMR) Data; Pathology Imaging/digital pathology; Computational Bioimaging; Genomic Measurements; Comparative analysis for metagenomes and genomes; Individualized Diabetes Management; Statistical Relational Artificial Intelligence for Health Care; World Population Scale Epidemiological Study; Social Contagion Modeling  for Planning, Public Health and Disaster Management and Biodiversity and LifeWatch.</p>"
13,51 Big Data Use Cases,9,Healthcare and Life Science Use Cases II,,,assets/slides/Lecture_13.pptx,y9zJzrH4P8k,"<p>This covers Electronic Medical Record (EMR) Data; Pathology Imaging/digital pathology; Computational Bioimaging; Genomic Measurements; Comparative analysis for metagenomes and genomes; Individualized Diabetes Management; Statistical Relational Artificial Intelligence for Health Care; World Population Scale Epidemiological Study; Social Contagion Modeling  for Planning, Public Health and Disaster Management and Biodiversity and LifeWatch.</p>"
13,51 Big Data Use Cases,10,Healthcare and Life Science Use Cases III,,,assets/slides/Lecture_13.pptx,eU5emeI3AmM,"<p>This covers Electronic Medical Record (EMR) Data; Pathology Imaging/digital pathology; Computational Bioimaging; Genomic Measurements; Comparative analysis for metagenomes and genomes; Individualized Diabetes Management; Statistical Relational Artificial Intelligence for Health Care; World Population Scale Epidemiological Study; Social Contagion Modeling  for Planning, Public Health and Disaster Management and Biodiversity and LifeWatch.</p>"
13,51 Big Data Use Cases,11,Deep Learning and Social Networks Use Cases,,,assets/slides/Lecture_13.pptx,WLSe6MF4ha4,"<p>This covers Large-scale Deep Learning; Organizing large-scale, unstructured collections of consumer photos; Truthy: Information diffusion research from Twitter Data; Crowd Sourcing in the Humanities as Source for Bigand Dynamic Data; CINET: Cyberinfrastructure for Network (Graph) Science and Analytics and NIST Information Access Division analytic technology performance measurement, evaluations, and standards.</p>"
13,51 Big Data Use Cases,12,Research Ecosystem Use Cases,,,assets/slides/Lecture_13.pptx,pZ6JucTCKcw,"<p>DataNet Federation Consortium DFC; The 'Discinnet process', metadata <-> big data global experiment; Semantic Graph-search on Scientific Chemical and Text-based Data and Light source beamlines.</p>"
13,51 Big Data Use Cases,13,Astronomy and Physics Use Cases I,,,assets/slides/Lecture_13.pptx,rWqkF-b3Kwk,"<p>This covers Catalina Real-Time Transient Survey (CRTS): a digital, panoramic, synoptic sky survey; DOE Extreme Data from Cosmological Sky Survey and Simulations; Large Survey Data for Cosmology; Particle Physics: Analysis of LHC Large Hadron Collider Data: Discovery of Higgs particle and Belle II High Energy Physics Experiment.</p>"
13,51 Big Data Use Cases,14,Astronomy and Physics Use Cases II,,,assets/slides/Lecture_13.pptx,RxLCB6yLmpk,"<p>This covers Catalina Real-Time Transient Survey (CRTS): a digital, panoramic, synoptic sky survey; DOE Extreme Data from Cosmological Sky Survey and Simulations; Large Survey Data for Cosmology; Particle Physics: Analysis of LHC Large Hadron Collider Data: Discovery of Higgs particle and Belle II High Energy Physics Experiment.</p>"
13,51 Big Data Use Cases,15,"Environment, Earth and Polar Science Use Cases I",,,assets/slides/Lecture_13.pptx,u2zTIGwsJwU,"<p>EISCAT 3D incoherent scatter radar system; ENVRI, Common Operations of Environmental Research Infrastructure; Radar Data Analysis for CReSIS Remote Sensing of Ice Sheets; UAVSAR Data Processing, DataProduct Delivery, and Data Services; NASA LARC/GSFC iRODS Federation Testbed; MERRA Analytic Services MERRA/AS; Atmospheric Turbulence - Event Discovery and Predictive Analytics; Climate Studies using the Community Earth System Model at DOE's NERSC center; DOE-BER Subsurface Biogeochemistry Scientific Focus Area and DOE-BER AmeriFlux and FLUXNET Networks.</p>"
13,51 Big Data Use Cases,16,"Environment, Earth and Polar Science Use Cases II",,,assets/slides/Lecture_13.pptx,sH3B3gXuJ7E,"<p>EISCAT 3D incoherent scatter radar system; ENVRI, Common Operations of Environmental Research Infrastructure; Radar Data Analysis for CReSIS Remote Sensing of Ice Sheets; UAVSAR Data Processing, DataProduct Delivery, and Data Services; NASA LARC/GSFC iRODS Federation Testbed; MERRA Analytic Services MERRA/AS; Atmospheric Turbulence - Event Discovery and Predictive Analytics; Climate Studies using the Community Earth System Model at DOE's NERSC center; DOE-BER Subsurface Biogeochemistry Scientific Focus Area and DOE-BER AmeriFlux and FLUXNET Networks.</p>"
13,51 Big Data Use Cases,17,Energy Use Case,,,assets/slides/Lecture_13.pptx,ttmVypmgWmw,<p>This covers Consumption forecasting in Smart Grids</p>
14,Features of 51 Big Data Use Cases,1,Summary of Use Case Classification I,,,assets/slides/Lecture_14.pptx,dfgH6YvHCGE,"<p>This discusses concepts used for parallelism and low and high level computational structure. Parallelism can be over People (users or subjects), Decision makers; Items such as Images, EMR, Sequences; observations, contents of online store; Sensors - Internet of Things; Events; (Complex) Nodes in a Graph; Simple nodes as in a learning network; Tweets, Blogs, Documents, Web Pages etc.; Files or data to be backed up, moved or assigned metadata; Particles/cells/mesh points. Low level computational types include PP (Pleasingly Parallel); MR (MapReduce); MRStat; MRIter (Iterative MapReduce); Graph; Fusion; MC (Monte Carlo) and Streaming. High level computational types include Classification; S/Q (Search and Query); Index; CF (Collaborative Filtering); ML (Machine Learning); EGO (Large Scale Optimizations); EM (Expectation maximization); GIS; HPC; Agents. Patterns include Classic Database; NoSQL; Basic processing of data as in backup or metadata; GIS; Host of Sensors processed on demand; Pleasingly parallel processing; HPC assimilated with observational data; Agent-based models; Multi-modal data fusion or Knowledge Management; Crowd Sourcing.</p>"
14,Features of 51 Big Data Use Cases,2,Summary of Use Case Classification II,,,assets/slides/Lecture_14.pptx,TjHus5-HaMQ,"<p>This discusses concepts used for parallelism and low and high level computational structure. Parallelism can be over People (users or subjects), Decision makers; Items such as Images, EMR, Sequences; observations, contents of online store; Sensors - Internet of Things; Events; (Complex) Nodes in a Graph; Simple nodes as in a learning network; Tweets, Blogs, Documents, Web Pages etc.; Files or data to be backed up, moved or assigned metadata; Particles/cells/mesh points. Low level computational types include PP (Pleasingly Parallel); MR (MapReduce); MRStat; MRIter (Iterative MapReduce); Graph; Fusion; MC (Monte Carlo) and Streaming. High level computational types include Classification; S/Q (Search and Query); Index; CF (Collaborative Filtering); ML (Machine Learning); EGO (Large Scale Optimizations); EM (Expectation maximization); GIS; HPC; Agents. Patterns include Classic Database; NoSQL; Basic processing of data as in backup or metadata; GIS; Host of Sensors processed on demand; Pleasingly parallel processing; HPC assimilated with observational data; Agent-based models; Multi-modal data fusion or Knowledge Management; Crowd Sourcing.</p>"
14,Features of 51 Big Data Use Cases,3,Summary of Use Case Classification III,,,assets/slides/Lecture_14.pptx,EbuNBbt4rQc,"<p>This discusses concepts used for parallelism and low and high level computational structure. Parallelism can be over People (users or subjects), Decision makers; Items such as Images, EMR, Sequences; observations, contents of online store; Sensors - Internet of Things; Events; (Complex) Nodes in a Graph; Simple nodes as in a learning network; Tweets, Blogs, Documents, Web Pages etc.; Files or data to be backed up, moved or assigned metadata; Particles/cells/mesh points. Low level computational types include PP (Pleasingly Parallel); MR (MapReduce); MRStat; MRIter (Iterative MapReduce); Graph; Fusion; MC (Monte Carlo) and Streaming. High level computational types include Classification; S/Q (Search and Query); Index; CF (Collaborative Filtering); ML (Machine Learning); EGO (Large Scale Optimizations); EM (Expectation maximization); GIS; HPC; Agents. Patterns include Classic Database; NoSQL; Basic processing of data as in backup or metadata; GIS; Host of Sensors processed on demand; Pleasingly parallel processing; HPC assimilated with observational data; Agent-based models; Multi-modal data fusion or Knowledge Management; Crowd Sourcing.</p>"
14,Features of 51 Big Data Use Cases,4,Database(SQL) Use Case Classification,,,assets/slides/Lecture_14.pptx,8QDcUWjA9Ok,<p>This discusses classic (SQL) datbase approach to data handling with Search&Query and Index features. Comparisons are made to NoSQL approaches</p>
14,Features of 51 Big Data Use Cases,5,NoSQL Use Case Classification,,,assets/slides/Lecture_14.pptx,aJ127gkHQUs,"<p>This discusses NoSQL (compared in previous lesson) with HDFS, Hadoop and Hbase. The Apache Big data stack is introduced and further details of comparison with SQL</p>"
14,Features of 51 Big Data Use Cases,6,Use Case Classifications I,,,assets/slides/Lecture_14.pptx,STAoaS1T2bM,"<p>This discusses a subset of use case features: GIS, Sensors. the support of data analysis and fusion by streaming data between filters.</p>"
14,Features of 51 Big Data Use Cases,7,Use Case Classifications II Part 1,,,assets/slides/Lecture_14.pptx,_tJRzG-jS4A,"<p>This discusses a subset of use case features: Pleasingly parallel, MRStat, Data Assimilation, Crowd sourcing, Agents, data fusion and agents, EGO and security.</p>"
14,Features of 51 Big Data Use Cases,8,Use Case Classifications II Part 2,,,assets/slides/Lecture_14.pptx,5iHdzMNviZo,"<p>This discusses a subset of use case features: Pleasingly parallel, MRStat, Data Assimilation, Crowd sourcing, Agents, data fusion and agents, EGO and security.</p>"
14,Features of 51 Big Data Use Cases,9,Use Case Classifications III Part 1,,,assets/slides/Lecture_14.pptx,tITbuwCRVzs,"<p>This discusses a subset of use case features: Classification,  Monte Carlo, Streaming, PP, MR, MRStat, MRIter and HPC(MPI), global and local analytics (machine learning), parallel computing, Expectation Maximization, graphs and Collaborative Filtering.</p>"
14,Features of 51 Big Data Use Cases,10,Use Case Classifications III Part 2,,,assets/slides/Lecture_14.pptx,0zaXWo8A4Co,"<p>This discusses a subset of use case features: Classification,  Monte Carlo, Streaming, PP, MR, MRStat, MRIter and HPC(MPI), global and local analytics (machine learning), parallel computing, Expectation Maximization, graphs and Collaborative Filtering.</p>"
15,Using Plotviz Software for Displaying Point Distributions in 3D,1,Motivation and Introduction to use,,,assets/slides/Lecture_15.pdf,4aQlCmQ1jfY,"<p>The motivation of Plotviz is that the human eye is very good at pattern recognition and can ''see'' structure in data. Although most Big data is higher dimensional than 3, all data can be transformed by dimension reduction techniques to 3D and one can check analysis like clustering and/or see structure missed in a computer analysis. The motivations shows some Cheminformatics examples. The use of Plotviz is started in slide 4 with a discussion of input file which is either a simple text or more features (like colors) can be specified in a rich XML syntax. Plotviz deals with points and their classification (clustering). Next the protein sequence browser in 3D shows the basic structure of Plotviz interface. The next two slides explain the core 3D and 2D manipulations respectively. Note all files used in examples are available to students.</p>"
15,Using Plotviz Software for Displaying Point Distributions in 3D,2,Example of Use I: Cube and Structured Dataset,,,assets/slides/Lecture_15.pdf,nCTT5mI_j_Q,<p>Initially we start with a simple plot of 8 points -- the corners of a cube in 3 dimensions -- showing basic operations such as size/color/labels and Legend of points. The second example shows a dataset (coming from GTM dimension reduction) with significant structure. This has .pviz and a .txt versions that are compared</p>
15,Using Plotviz Software for Displaying Point Distributions in 3D,3,Example of Use II: Proteomics and Synchronized Rotation,,,assets/slides/Lecture_15.pdf,lDbIhnLrNkk,<p>This starts with an examination of a sample of Protein Universe Browser showing how one uses Plotviz to look at different features of this set  of Protein sequences projected to 3D. Then we show how to compare two datasets with synchronized rotation of a dataset clustered in 2 different ways; this dataset comes from k Nearest Neighbor discussion</p>
15,Using Plotviz Software for Displaying Point Distributions in 3D,4,Example of Use III:  More Features and larger Proteomics Sample,,,assets/slides/Lecture_15.pdf,KBkUW_QNSvs,<p>This starts by describing use of Labels and Glyphs and the Default mode in Plotviz. Then we illustrate sophisticated use of these ideas to view a large Proteomics dataset</p>
15,Using Plotviz Software for Displaying Point Distributions in 3D,5,Example of Use IV:  Tools and Examples,,,assets/slides/Lecture_15.pdf,zp_709imR40,<p>This lesson starts by describing the Plotviz tools and then sets up two examples -- Oil Flow and Trading -- described in PowerPoint. It finishes with the Plotviz viewing of Oil Flow data</p>
15,Using Plotviz Software for Displaying Point Distributions in 3D,6,Example of Use V: Final Examples,,,assets/slides/Lecture_15.pdf,FKoCfTJ_cDM,<p>This starts with Plotviz looking at Trading example introduced in previous lesson and them examines solvent data. It finishes with two large biology examples with 446K and 100K points and each with over 100 clusters. We finish remarks on Plotviz software structure and how to download. We also remind you that a picture is worth a 1000 words</p>
16,Recommender Systems: Introduction,1,Recommender Systems as an Optimization Problem,,,assets/slides/Lecture_16.pptx,rymBt1kdyVU,"<p>We define a set of general recommender systems as matching of items to people or perhaps collections of items to collections of people where items can be other people, products in a store, movies, jobs, events, web pages etc. We present this as ''yet another optimization problem''</p>"
16,Recommender Systems: Introduction,2,Recommender Systems Introduction,,,assets/slides/Lecture_16.pptx,KbjBKrzFYKg,<p>We give a general discussion of recommender systems and point out that they are particularly valuable in long tail of tems (to be recommended) that aren't commonly known. We pose them as a rating system and relate them to information retrieval rating systems. We can contrast recommender systems based on user profile and context; the most familiar collaborative filtering of others ranking; item properties; knowledge and hybrid cases mixing some or all of these.</p>
16,Recommender Systems: Introduction,3,Kaggle Competitions,,,assets/slides/Lecture_16.pptx,DFH7GPrbsJA,<p>We look at Kaggle competitions with examples from web site. In particular we discuss an Irvine class project involving ranking jokes</p>
16,Recommender Systems: Introduction,4,Examples of Recommender Systems,,,assets/slides/Lecture_16.pptx,1Eh1epQj-EQ,<p>We go through a list of 9 recommender systems from the same Irvine class</p>
16,Recommender Systems: Introduction,5,Netflix on Recommender Systems I,,,assets/slides/Lecture_16.pptx,tXsU5RRAD-w,"<p>We summarize some interesting points from a tutorial from Netflix for whom ''everything is a recommendation''. Rankings are given in multiple categories and categories that reflect user interests are especially important. Criteria used include explicit user preferences, implicit based on ratings and hybrid methods as well as freshness and diversity. Netflix tries to explain the rationale of its recommendations. We give some data on Netflix operations and some methods used in its recommender systems. We describe the famous Netflix Kaggle competition to improve its rating system. The analogy to maximizing click through rate is given and the objectives of optimization are given.</p>"
16,Recommender Systems: Introduction,6,Netflix on Recommender Systems II,,,assets/slides/Lecture_16.pptx,GnAol5aGuEo,"<p>We summarize some interesting points from a tutorial from Netflix for whom ''everything is a recommendation''. Rankings are given in multiple categories and categories that reflect user interests are especially important. Criteria used include explicit user preferences, implicit based on ratings and hybrid methods as well as freshness and diversity. Netflix tries to explain the rationale of its recommendations. We give some data on Netflix operations and some methods used in its recommender systems. We describe the famous Netflix Kaggle competition to improve its rating system. The analogy to maximizing click through rate is given and the objectives of optimization are given.</p>"
16,Recommender Systems: Introduction,7,Consumer Data Science,,,assets/slides/Lecture_16.pptx,B8cjaOQ57LI,"<p>Here we go through Netflix's methodology in letting data speak for itself in optimizing the recommender engine. An example iis given on choosing self produced movies. A/B testing is discussed with examples showing how testing does allow optimizing of sophisticated criteria. This lesson is concluded by comments on Netflix technology and the full spectrum of issues that are involved including user interface, data, AB testing, systems and architectures. We comment on optimizing for a household rather than optimizing for individuals in household.</p>"
17,Recommender Systems: Examples and Algorithms,1,Recap and Examples of Recommender Systems,,,assets/slides/Lecture_17.pptx,dcdm5AfGZ64,<p>We start with a quick recap of recommender systems from previous unit; what they are with brief examples.</p>
17,Recommender Systems: Examples and Algorithms,2,Examples of Recommender Systems,,,assets/slides/Lecture_17.pptx,og07mH9fU0M,<p>We give 2 examples in more detail: namely Google News and Markdown in Retail.</p>
17,Recommender Systems: Examples and Algorithms,3,Recommender Systems in Yahoo Use Case Example I,,,assets/slides/Lecture_17.pptx,FBn7HpGFNvg,"<p>We describe in greatest detail the methods used to optimize Yahoo web sites. There are two lessons discussing general approach and a third lesson examines a particular personalized Yahoo page with its different components. We point out the different criteria that must be blended in making decisions; these criteria include analysis of what user does after a particular page is clicked; is the user satisfied and cannot that we quantified by purchase decisions etc. We need to choose Articles, ads, modules, movies, users, updates, etc to optimize metrics such as relevance score, CTR, revenue, engagement.These lesson stress that if though we have big data, the recommender data is sparse. We discuss the approach that involves both batch (offline) and on-line (real time) components</p>"
17,Recommender Systems: Examples and Algorithms,4,Recommender Systems in Yahoo Use Case Example II,,,assets/slides/Lecture_17.pptx,VS2Y4lAiP5A,"<p>We give some examples in more detail including Google News, Markdown in Retail and in greatest detail the methods used to optimize a Yahoo page. Here we review recommender engines yet again put then examine a personalized Yahoo page with its different components. We point out the different criteria that must be blended in making decisions; these criteria include analysis of what user does after a particular page is clicked; is the user satisfied and cannot that we quantified by purchase decisions etc. We need to choose Articles, ads, modules, movies, users, updates, etc to optimize metrics such as relevance score, CTR, revenue, engagement.This lesson stresses that if though we have big data, the recommender data is sparse. We discuss the approach that involves both batch (offline) and on-line (real time) components</p>"
17,Recommender Systems: Examples and Algorithms,5,Recommender Systems in Yahoo Use Case Example III: Particular Module,,,assets/slides/Lecture_17.pptx,HrRJWEF8EfU,"<p>We describe in greatest detail the methods used to optimize Yahoo web sites. There are two lessons discussing general approach and a third lesson examines a particular personalized Yahoo page with its different components. We point out the different criteria that must be blended in making decisions; these criteria include analysis of what user does after a particular page is clicked; is the user satisfied and cannot that we quantified by purchase decisions etc. We need to choose Articles, ads, modules, movies, users, updates, etc to optimize metrics such as relevance score, CTR, revenue, engagement.These lesson stress that if though we have big data, the recommender data is sparse. We discuss the approach that involves both batch (offline) and on-line (real time) components</p>"
17,Recommender Systems: Examples and Algorithms,6,User-based nearest-neighbor collaborative filtering I,,,assets/slides/Lecture_17.pptx,lsf_AE-8dSk,"<p>Collaborative filtering is a core approach to recommender systems. There is user-based and item-based collaborative filtering and here we discuss the user-based case. Here similarities in user rankings allow one to predict their interests, and typically this quantified by the Pearson correlation, used to statistically quantify correlations between users.</p>"
17,Recommender Systems: Examples and Algorithms,7,User-based nearest-neighbor collaborative filtering I,,,assets/slides/Lecture_17.pptx,U7-qeX2ItPk,"<p>Collaborative filtering is a core approach to recommender systems. There is user-based and item-based collaborative filtering and here we discuss the user-based case. Here similarities in user rankings allow one to predict their interests, and typically this quantified by the Pearson correlation, used to statistically quantify correlations between users.</p>"
17,Recommender Systems: Examples and Algorithms,8,Vector Space Formulation of Recommender Systems,,,assets/slides/Lecture_17.pptx,IlQUZOXlaSU,<p>We go through recommender systems thinking of them as formulated in a funny vector space. This suggests using clustering to make recommendations.</p>
18,Item-based Collaborative Filtering and its Technologies,1,Item-based Collaborative Filtering I,,,assets/slides/Lecture_18.pptx,25sBgh3HwxY,<p>We covered user-based collaborative filtering in the previous unit. Here we start by discussing memory-based real time and model based offline (batch) approaches. Now we look at item-based collaborative filtering where items are viewed in the space of users and the cosine measure is used to quantify distances. WE discuss optimizations and how batch processing can help. We discuss different Likert ranking scales and issues with new items that do not have a significant number of rankings.</p>
18,Item-based Collaborative Filtering and its Technologies,2,Item-based Collaborative Filtering II,,,assets/slides/Lecture_18.pptx,SM8EJdAa4mw,<p>We covered user-based collaborative filtering in the previous unit. Here we start by discussing memory-based real time and model based offline (batch) approaches. Now we look at item-based collaborative filtering where items are viewed in the space of users and the cosine measure is used to quantify distances. WE discuss optimizations and how batch processing can help. We discuss different Likert ranking scales and issues with new items that do not have a significant number of rankings.</p>
18,Item-based Collaborative Filtering and its Technologies,3,k Nearest Neighbors and High Dimensional Spaces,,,assets/slides/Lecture_18.pptx,2NqUsDGQDy8,"<p>We define the k Nearest Neighbor algorithms and present the Python software but do not use it. We give examples from Wikipedia and describe performance issues. This algorithm illustrates the curse of dimensionality. If items were a real vectors in a low dimension space, there would be faster solution methods.</p>"
19,Recommender Systems - K-Nearest Neighbors (Python & Java Track),1,Python k'th Nearest Neighbor Algorithms I,,,assets/slides/Lecture_19.pptx,o16L0EqsQ_g,<p>This lesson considers the Python k Nearest Neighbor code found on the web associated with a book by Harrington on Machine Learning. There are two data sets. First we consider a set of 4 2D vectors divided into two categories (clusters) and use k=3 Nearest Neighbor algorithm to classify 3 test points. Second we consider a 3D dataset that has already been classified and show how to normalize. In this lesson we just use Matplotlib to give 2D plots</p>
19,Recommender Systems - K-Nearest Neighbors (Python & Java Track),2,Python k'th Nearest Neighbor Algorithms II,,,assets/slides/Lecture_19.pptx,JK5p24mnTjs,<p>This lesson considers the Python k Nearest Neighbor code found on the web associated with a book by Harrington on Machine Learning. There are two data sets. First we consider a set of 4 2D vectors divided into two categories (clusters) and use k=3 Nearest Neighbor algorithm to classify 3 test points. Second we consider a 3D dataset that has already been classified and show how to normalize. In this lesson we just use Matplotlib to give 2D plots</p>
19,Recommender Systems - K-Nearest Neighbors (Python & Java Track),3,3D Visualization,,Codifying k-NN,assets/slides/Lecture_19.pptx,fLtH-ZI1Jqk,<p>The lesson modifies the online code to allow it to produce files readable by PlotViz. We visualize already classified 3D set and rotate in 3D.</p>
19,Recommender Systems - K-Nearest Neighbors (Python & Java Track),4,Testing k'th Nearest Neighbor Algorithms,,Codifying k-NN,assets/slides/Lecture_19.pptx,zLaPGMIQ9So,<p>The lesson goes through an example of using k NN classification algorithm by dividing dataset into 2 subsets. One is training set with initial classification; the other is test point to be classified by k=3 NN using training set. The code records fraction of points with a different classification from that input. One can experiment with different sizes of the two subsets. The Python implementation of algorithm is analyzed in detail.</p>
20,Clustering and heuristic methods,1,Kmeans Clustering,,,assets/slides/Lecture_20.pdf,3KTNJ0Okrqs,<p>Geoffrey introduces the k means algorithm in a gentle fashion and describes its key features including dangers of local minima. A simple example from Wikipedia is examined</p>
20,Clustering and heuristic methods,2,Clustering of Recommender System Example,,,assets/slides/Lecture_20.pdf,yl_KZ86NT-A,<p>Plotviz is used to examine and compare the original classification with an ''optimal'' clustering into 3 clusters using a fancy deterministic annealing method that is similar to k means. The new clustering has centers marked</p>
20,Clustering and heuristic methods,3,Clustering of Recommender Example into more than 3 Clusters,,,assets/slides/Lecture_20.pdf,JWZmh48l0cw,<p>The previous division into 3 clusters is compared into a clustering into 28 separate clusters that are naturally smaller in size and divide 3D space covered by 1000 points into compact geometrically local regions.</p>
20,Clustering and heuristic methods,4,Local Optima in Clustering,,,assets/slides/Lecture_20.pdf,Zmq8O_axCmc,<p>This lesson introduces some general principles. First many important processes are ''just'' optimization problems. Most such problems are rife with local optima. The key idea behind annealing to avoid local optima is described. The pervasive greedy optimization method is described.</p>
20,Clustering and heuristic methods,5,Clustering in General,,,assets/slides/Lecture_20.pdf,JejNZhBxjRU,<p>The two different applications of clustering are described. First find geometrically distinct regions and secondly divide spaces into geometrically compact regions that may have no ''thin air'' between them. Generalizations such as mixture models and latent factor methods are just mentioned. The important distinction between applications in vector spaces and those where only inter-point distances are defined is described. Examples are then given using PlotViz from 2D clustering of a mass spectrometry example and the results of clustering genomic data mapped into 3D with Multi Dimensional Scaling MDS.</p>
20,Clustering and heuristic methods,6,Heuristics,,,assets/slides/Lecture_20.pdf,KT22YuX8ZMY,<p>Some remarks are given on heuristics; why are they so important why getting exact answers is often not so important?</p>
21,Parallel Computing: Overview of Basic Principles with familiar Examples,1,Decomposition I,,,assets/slides/Lecture_21.pdf,R-wHQW2YuRE,"<p>Geoffrey describes why parallel computing is essential with Big Data and distinguishes parallelism over users to that over the data in problem. The general ideas behind data decomposition are given followed by a few often whimsical examples dreamed up 30 years ago in the early heady days of parallel computing. These include scientific simulations, defense outside missile attack and computer chess. The basic problem of parallel computing -- efficient coordination of separate tasks processing different data parts --  is described with MPI and MapReduce as two approaches. The challenges of data decomposition in irregular problems is noted.</p>"
21,Parallel Computing: Overview of Basic Principles with familiar Examples,2,Decomposition II,,,assets/slides/Lecture_21.pdf,iIi9wdvlwCM,"<p>Geoffrey describes why parallel computing is essential with Big Data and distinguishes parallelism over users to that over the data in problem. The general ideas behind data decomposition are given followed by a few often whimsical examples dreamed up 30 years ago in the early heady days of parallel computing. These include scientific simulations, defense outside missile attack and computer chess. The basic problem of parallel computing -- efficient coordination of separate tasks processing different data parts --  is described with MPI and MapReduce as two approaches. The challenges of data decomposition in irregular problems is noted.</p>"
21,Parallel Computing: Overview of Basic Principles with familiar Examples,3,Decomposition III,,,assets/slides/Lecture_21.pdf,F0aeeLeTD9I,"<p>Geoffrey describes why parallel computing is essential with Big Data and distinguishes parallelism over users to that over the data in problem. The general ideas behind data decomposition are given followed by a few often whimsical examples dreamed up 30 years ago in the early heady days of parallel computing. These include scientific simulations, defense outside missile attack and computer chess. The basic problem of parallel computing -- efficient coordination of separate tasks processing different data parts --  is described with MPI and MapReduce as two approaches. The challenges of data decomposition in irregular problems is noted.</p>"
21,Parallel Computing: Overview of Basic Principles with familiar Examples,4,Parallel Computing in Society I,,,assets/slides/Lecture_21.pdf,8rtjoe8AeJw,<p>This lesson from the past notes that one can view society as an approach to parallel linkage of people. The largest example given is that of the construction of a long wall such as that (Hadrian's wall) between England and Scotland. Different approaches to parallelism are given with formulae for the speed up and efficiency. The concepts of grain size (size of problem tackled by an individual processor) and coordination overhead are exemplified. This example also illustrates Amdahl's law and the relation between data and processor topology. The lesson concludes with other examples from nature including collections of neurons (the brain) and ants.</p>
21,Parallel Computing: Overview of Basic Principles with familiar Examples,5,Parallel Computing in Society II,,,assets/slides/Lecture_21.pdf,7sCgH_TTPGk,<p>This lesson from the past notes that one can view society as an approach to parallel linkage of people. The largest example given is that of the construction of a long wall such as that (Hadrian's wall) between England and Scotland. Different approaches to parallelism are given with formulae for the speed up and efficiency. The concepts of grain size (size of problem tackled by an individual processor) and coordination overhead are exemplified. This example also illustrates Amdahl's law and the relation between data and processor topology. The lesson concludes with other examples from nature including collections of neurons (the brain) and ants.</p>
21,Parallel Computing: Overview of Basic Principles with familiar Examples,6,Parallel Processing for Hadrian's Wall,,,assets/slides/Lecture_21.pdf,ZD2AQ08cy8I,<p>This lesson returns to Hadrian's wall and uses it to illustrate advanced issues in parallel computing. First Geoffrey describes the basic SPMD -- Single Program Multiple Data -- model. Then irregular but homogeneous and heterogeneous problems are discussed. Static and dynamic load balancing is needed. Inner parallelism (as in vector instruction or the multiple fingers of masons) and outer parallelism (typical data parallelism) are demonstrated. Parallel I/O for Hadrian's wall is followed by a slide summarizing this quaint comparison between Big data parallelism and the construction of a large wall.</p>
22,Cloud Technology Part I: Introduction,1,Cyberinfrastructure for E-MoreOrLessAnything,,,assets/slides/Lecture_22.pptx,mX4RFZLLU34,<p>This introduction describes Cyberinfrastructure or e-infrastructure and its role in solving the electronic implementation of any problem where e-moreorlessanything is another term for moreorlessanything-Informatics and generalizes early discussion of e-Science and e-Business.</p>
22,Cloud Technology Part I: Introduction,2,What is Cloud Computing: Introduction,,,assets/slides/Lecture_22.pptx,Od_mYXRs5As,"<p>Cloud Computing is introduced with an operational definition involving virtualization and efficient large data centers that can rent computers in an elastic fashion. The role of services is essential -- it underlies capabilities being offered in the cloud. The four basic aaS's -- Software (SaaS), Platform (Paas), Infrastructure (IaaS) and Network (NaaS) -- are introduced with Research aaS and other capabilities (for example Sensors aaS are discussed later) being built on top of these.</p>"
22,Cloud Technology Part I: Introduction,3,What and Why  is Cloud Computing: Several Other Views I,,,assets/slides/Lecture_22.pptx,5VeqMjXKU_Y,<p>This lesson contains 5 slides with diverse comments on ''what is cloud computing'' from the web.</p>
22,Cloud Technology Part I: Introduction,4,What and Why  is Cloud Computing: Several Other Views II,,,assets/slides/Lecture_22.pptx,J963LR0PS_g,<p>This lesson contains 5 slides with diverse comments on ''what is cloud computing'' from the web.</p>
22,Cloud Technology Part I: Introduction,5,What and Why  is Cloud Computing: Several Other Views III,,,assets/slides/Lecture_22.pptx,_ryLXUnOAzo,<p>This lesson contains 5 slides with diverse comments on ''what is cloud computing'' from the web.</p>
22,Cloud Technology Part I: Introduction,6,Gartner's Emerging Technology Landscape for Clouds and Big Data,,,assets/slides/Lecture_22.pptx,N7aEtU1mUwc,"<p>This lesson gives Gartner's projections around futures of cloud and Big data. We start with a review of hype charts and then go into detailed Gartner analyses of the Cloud and Big data areas. Big data itself is at the top of the hype and by definition predictions of doom are emerging. Before too much excitement sets in, note that spinach is above clouds and Big data in Google trends.</p>"
22,Cloud Technology Part I: Introduction,7,Simple Examples of use of Cloud Computing,,,assets/slides/Lecture_22.pptx,VCctCP6BKEo,<p>This short lesson gives two examples of rather straightforward commercial applications of cloud computing. One is server consolidation for multiple Microsoft database applications and the second is the benefits of scale comparing gmail to multiple smaller installations. It ends with some fiscal comments</p>
22,Cloud Technology Part I: Introduction,8,Value of Cloud Computing,,,assets/slides/Lecture_22.pptx,HM1dZCxdsaA,<p>Some comments on fiscal value of cloud computing</p>
23,Cloud Technology Part II: Software and Systems,1,What is Cloud Computing: Applications and Architectures,,,assets/slides/Lecture_23.pptx,h3Rpb0Eyj1c,<p>This lesson gives some general remark of cloud systems from an architecture and application perspective.</p>
23,Cloud Technology Part II: Software and Systems,2,Introduction to Cloud Software Architecture: IaaS and PaaS I,,,assets/slides/Lecture_23.pptx,1AnyJYyh490,<p>Geoffrey discusses cloud software for the cloud starting at virtual machine management (IaaS) and the broad Platform (middleware) capabilities with examples from Amazon and academic studies.</p>
23,Cloud Technology Part II: Software and Systems,3,Introduction to Cloud Software Architecture: IaaS and PaaS II,,,assets/slides/Lecture_23.pptx,hVpFAUHcAd4,<p>Geoffrey discusses cloud software for the cloud starting at virtual machine management (IaaS) and the broad Platform (middleware) capabilities with examples from Amazon and academic studies.</p>
23,Cloud Technology Part II: Software and Systems,4,Data in the Cloud,,,assets/slides/Lecture_23.pptx,HdtIOnk3qX4,"<p>Databases, File systems, Object Stores and NOSQL are discussed and compared. The way to build a modern data repository in the cloud is introduced.</p>"
24,Cloud Computing Technology Part III: Architectures and Applications,1,Cloud (Data Center) Architectures I,,,assets/slides/Lecture_24.pptx,j0P32DmQjI8,"<p>Some remarks on what it takes to build (in software) a cloud ecosystem, and why clouds are the data center of the future are followed by pictures and discussions of several data centers from Microsoft (mainly) and Google. The role of containers is stressed as part of modular data centers that trade scalability for fault tolerance. Sizes of cloud centers and supercomputers are discussed as is ''green'' computing.</p>"
24,Cloud Computing Technology Part III: Architectures and Applications,2,Cloud (Data Center) Architectures II,,,assets/slides/Lecture_24.pptx,3HAGqz34AB4,"<p>Some remarks on what it takes to build (in software) a cloud ecosystem, and why clouds are the data center of the future are followed by pictures and discussions of several data centers from Microsoft (mainly) and Google. The role of containers is stressed as part of modular data centers that trade scalability for fault tolerance. Sizes of cloud centers and supercomputers are discussed as is ''green'' computing.</p>"
24,Cloud Computing Technology Part III: Architectures and Applications,3,Cloud applications I,,,assets/slides/Lecture_24.pptx,nkeSOMTGbbo,"<p>This lesson starts with some general principle and commercial success stories. It continues with a classification of applications and an identification of what will run on clouds, grids, high throughput systems and supercomputers. Results from Venus-C and the Microsoft Excel Datascope are discussed. The latter illustrates the suitability of many data intensive problems for cloud computing. Clouds are also especially relevant in pleasing parallel applications and the lower parts of the famous computing pyramid; the very many modest size applications.</p>"
24,Cloud Computing Technology Part III: Architectures and Applications,4,Cloud applications II,,,assets/slides/Lecture_24.pptx,ORd3aBhc2Rc,"<p>This lesson starts with some general principle and commercial success stories. It continues with a classification of applications and an identification of what will run on clouds, grids, high throughput systems and supercomputers. Results from Venus-C and the Microsoft Excel Datascope are discussed. The latter illustrates the suitability of many data intensive problems for cloud computing. Clouds are also especially relevant in pleasing parallel applications and the lower parts of the famous computing pyramid; the very many modest size applications.</p>"
24,Cloud Computing Technology Part III: Architectures and Applications,5,Security,,,assets/slides/Lecture_24.pptx,NojXG3fbrEo,<p>This short lesson discusses the need for security and issues in its implementation.</p>
24,Cloud Computing Technology Part III: Architectures and Applications,6,Comments on Fault Tolerance and Synchronicity Constraints,,,assets/slides/Lecture_24.pptx,OMZiSiN7dlU,<p>Clouds trade scalability for greater possibility of faults but here clouds offer good support for recovery from faults. We discuss both storage and program fault tolerance noting that parallel computing is especially sensitive to faults as a fault in one task will impact all other tasks in the parallel job.</p>
24,Cloud Computing Technology Part III: Architectures and Applications,7,Big Data Processing (From Application Perspective; Technology discussed in previous unit),,,assets/slides/Lecture_24.pptx,d6A2m4GR-hw,"<p>This lesson collects remarks on Big data processing from several sources: Berkeley, Teradata, IBM, Oracle and eBay with architectures and application opportunities.</p>"
25,Web Search and Text Mining I,1,Web and Document/Text Search: The Problem,,,assets/slides/Lecture_25.pptx,T12BccKe8p4,"<p>This lesson starts with the web with its size, shape (coming from the mutual linkage of pages by URL's) and universal power laws for number of pages with particular number of URL's linking out or in to page.</p>"
25,Web Search and Text Mining I,2,Information Retrieval leading to Web Search,,,assets/slides/Lecture_25.pptx,KtWhk2cdRa4,<p>Information retrieval is introduced  A comparison is given between semantic searches as in databases and the full text search that is base of Web search. The ACM classification illustrates potential complexity of ontologies. Some differences between web search and information retrieval are given.</p>
25,Web Search and Text Mining I,3,History behind Web Search,,,assets/slides/Lecture_25.pptx,J7D61uH5gVM,"<p>The origin of web search in libraries, catalogs and concordances is summarized.</p>"
25,Web Search and Text Mining I,4,Key Fundamental Principles behind Web Search,,,assets/slides/Lecture_25.pptx,yPFi6xFnDHE,"<p>This lesson describes the DIKW -- Data Information Knowledge Wisdom -- model for web search. Then it discusses documents, collections and the important Bag of Words representation.</p>"
25,Web Search and Text Mining I,5,Information Retrieval (Web Search) Components,,,assets/slides/Lecture_25.pptx,EGsnonXgb3Y,"<p>This describes queries in context of an Information Retrieval architecture. The method of judging quality of results including recall, precision and diversity is described.</p>"
25,Web Search and Text Mining I,6,Search Engines,,,assets/slides/Lecture_25.pptx,kBV-99N6f7k,<p>This short lesson describes a time line for evolution of search engines. The first web search approaches were directly built on Information retrieval but in 1998 the field was changed when Google was founded and showed the importance of URL structure as exemplified by PageRank.</p>
25,Web Search and Text Mining I,7,Boolean and Vector Space Models,,,assets/slides/Lecture_25.pptx,JzGBA0OhsIk,<p>This lesson describes the Boolean and Vector Space models for query including the cosine similarity</p>
25,Web Search and Text Mining I,8,Web crawling and Document Preparation,,,assets/slides/Lecture_25.pptx,Wv-r-PJ9lro,<p>This describes a Web Crawler and then the steps needed to analyze data from Web and produce a set of terms</p>
25,Web Search and Text Mining I,9,Indices,,,assets/slides/Lecture_25.pptx,NY2SmrHoBVM,<p>This lesson describes both building and accessing an inverted index. It describes how phrases are treated and gives details of query structure from some early logs</p>
25,Web Search and Text Mining I,10,TF-IDF and Probabilistic Models,,,assets/slides/Lecture_25.pptx,9P_HUmpselU,<p>It describes the importance of term specificity and how it is captured in TF-IDF. It notes how frequencies are converted into belief and relevance</p>
26,Web Search and Text Mining II,1,Data Analytics for Web Search,,,assets/slides/Lecture_26.pptx,ugyycKBjaBQ,"<p>This short lesson describes the different steps needed in web search including: Get the digital data (from web or from scanning); Crawl web; Preprocess data to get searchable things (words, positions); Form Inverted Index mapping words to documents; Rank relevance of documents with potentially sophisticated techniques; and integrate technology to support advertising and ways to allow or stop pages artificially enhancing relevance.</p>"
26,Web Search and Text Mining II,2,Link Structure Analysis including PageRank I,,,assets/slides/Lecture_26.pptx,1oXdopVxqfI,<p>The value of links and the concepts of Hubs and Authorities are discussed. This leads to definition of PageRank with examples. Extensions of PageRank viewed as a reputation are discussed with journal rankings and university department rankings as examples. There are many extension of these ideas which are not discussed here although topic models are covered briefly in a later lesson.</p>
26,Web Search and Text Mining II,3,Link Structure Analysis including PageRank II,,,assets/slides/Lecture_26.pptx,OCn-gCTxvrU,<p>The value of links and the concepts of Hubs and Authorities are discussed. This leads to definition of PageRank with examples. Extensions of PageRank viewed as a reputation are discussed with journal rankings and university department rankings as examples. There are many extension of these ideas which are not discussed here although topic models are covered briefly in a later lesson.</p>
26,Web Search and Text Mining II,4,Web Advertising and Search,,,assets/slides/Lecture_26.pptx,GgkmG0NzQvg,"<p>Internet and mobile advertising is growing fast and can be personalized more than for traditional media. There are several advertising types Sponsored search, Contextual ads, Display ads and different models: Cost per viewing, cost per clicking and cost per action. This leads to emerging field of computational advertising.</p>"
26,Web Search and Text Mining II,5,Clustering and Topic Models,,,assets/slides/Lecture_26.pptx,95cHMyZ-TUs,<p>We discuss briefly approaches to defining groups of documents. We illustrate this for Google News and give an example that this can give different answers from word-based analyses. We mention some work at Indiana University on a Latent Semantic Indexing model.</p>
27,Technology for X-Informatics: PageRank (Python & Java Track),1,Calculate PageRank from Web Linkage Matrix I,,,assets/slides/Lecture_27.pptx,rLWUvvcHrCQ,<p>Geoffrey takes two simple matrices for 6 and 8 web sites respectively to illustrate the calculation of PageRank.</p>
27,Technology for X-Informatics: PageRank (Python & Java Track),2,Calculate PageRank from Web Linkage Matrix II,,,assets/slides/Lecture_27.pptx,UzQRukCFQv8,<p>Geoffrey takes two simple matrices for 6 and 8 web sites respectively to illustrate the calculation of PageRank.</p>
27,Technology for X-Informatics: PageRank (Python & Java Track),3,Calculate PageRank of a real page,,Three Other Methods,assets/slides/Lecture_27.pptx,8L_72bRLQVk,<p>This tiny lesson presents a Python code that finds the Page Rank that Google calculates for any page on the web</p>
28,Technology for X-Informatics: K-means (Python & Java Track),1,K-means in Python,,,assets/slides/Lecture_28.pptx,I79ISV6XBbE,<p>Geoffrey uses the K-means Python code in SciPy package to show real code for clustering and applies it a set of 85 two dimensional vectors -- officially sets of weights and heights to be clustered to find T-shirt sizes. We run through Python code with Matplotlib displays to divide into 2-5 clusters. Then we discuss Python to generate 4 clusters of varying sizes and centered at corners of a square in two dimensions. We formally give the K means algorithm better than before and make definition consistent with code in SciPy</p>
28,Technology for X-Informatics: K-means (Python & Java Track),2,Analysis of 4 Artificial Clusters I,,,assets/slides/Lecture_28.pptx,Srgq9VDg4C8,<p>We present clustering results on the artificial set of 1000 2D points described in previous lesson for 3 choices of cluster  sizes ''small'' ''large'' and ''very large''. We emphasize the SciPy always does 20 independent K means and takes the best result -- an approach to avoiding local minima. We allow this number of independent runs to be changed and in particular set to 1 to generate more interesting erratic results. We define changes in our new K means code that also has two measures of quality allowed. The slides give many results of clustering into 2 4 6 and 8 clusters (there were only 4 real clusters). We show that the ''very small'' case has two very different solutions when clustered into two clusters and use this to discuss functions with multiple minima and a hill between them. The lesson has both discussion of already produced results in slides and interactive use of Python for new runs.</p>
28,Technology for X-Informatics: K-means (Python & Java Track),3,Analysis of 4 Artificial Clusters II,,,assets/slides/Lecture_28.pptx,rjyAXjA_mOk,<p>We present clustering results on the artificial set of 1000 2D points described in previous lesson for 3 choices of cluster  sizes ''small'' ''large'' and ''very large''. We emphasize the SciPy always does 20 independent K means and takes the best result -- an approach to avoiding local minima. We allow this number of independent runs to be changed and in particular set to 1 to generate more interesting erratic results. We define changes in our new K means code that also has two measures of quality allowed. The slides give many results of clustering into 2 4 6 and 8 clusters (there were only 4 real clusters). We show that the ''very small'' case has two very different solutions when clustered into two clusters and use this to discuss functions with multiple minima and a hill between them. The lesson has both discussion of already produced results in slides and interactive use of Python for new runs.</p>
28,Technology for X-Informatics: K-means (Python & Java Track),4,Analysis of 4 Artificial Clusters III,,,assets/slides/Lecture_28.pptx,N6QKyrhNVAc,<p>We present clustering results on the artificial set of 1000 2D points described in previous lesson for 3 choices of cluster  sizes ''small'' ''large'' and ''very large''. We emphasize the SciPy always does 20 independent K means and takes the best result -- an approach to avoiding local minima. We allow this number of independent runs to be changed and in particular set to 1 to generate more interesting erratic results. We define changes in our new K means code that also has two measures of quality allowed. The slides give many results of clustering into 2 4 6 and 8 clusters (there were only 4 real clusters). We show that the ''very small'' case has two very different solutions when clustered into two clusters and use this to discuss functions with multiple minima and a hill between them. The lesson has both discussion of already produced results in slides and interactive use of Python for new runs.</p>
29,Technology for X-Informatics: MapReduce,1,Introduction,,,assets/slides/Lecture_29.pptx,67qFY64aj7g,<p>This introduction uses an analogy to making fruit punch by slicing and blending fruit to illustrate MapReduce. The formal structure of MapReduce and Iterative MapReduce is presented with parallel data flowing from disks through multiple Map and Reduce phases to be inspected by the user</p>
29,Technology for X-Informatics: MapReduce,2,Advanced Topics I,,,assets/slides/Lecture_29.pptx,lo4movzSyVw,<p>This defines 4 types of MapReduce and the Map Collective model of Qiu. The  Iterative MapReduce model from Indiana University called Twister is described and a few performance measurements on Microsoft Azure are presented.</p>
29,Technology for X-Informatics: MapReduce,3,Advanced Topics II,,,assets/slides/Lecture_29.pptx,wnanWncQBow,<p>This defines 4 types of MapReduce and the Map Collective model of Qiu. The  Iterative MapReduce model from Indiana University called Twister is described and a few performance measurements on Microsoft Azure are presented.</p>
30,Technology for X-Informatics: Kmeans and MapReduce Parallelism (Python & Java Track),1,MapReduce Kmeans in Python I,,,assets/slides/Lecture_30.pptx,2El1oL3gKpQ,<p>Geoffrey modifies the SciPy K-means code to support a MapReduce execution style and runs it in this short unit. This illustrates the key ideas of mappers and reducers. With appropriate runtime this code would run in parallel but here the ''parallel'' maps run sequentially. Geoffrey stresses that this simple 2 map version can be generalized to scalable parallelism.</p>
30,Technology for X-Informatics: Kmeans and MapReduce Parallelism (Python & Java Track),2,MapReduce Kmeans in Python II,,MapReduce Kmeans in Python II,assets/slides/Lecture_30.pptx,LLrTWWdE3T0,<p>Geoffrey modifies the SciPy K-means code to support a MapReduce execution style and runs it in this short unit. This illustrates the key ideas of mappers and reducers. With appropriate runtime this code would run in parallel but here the ''parallel'' maps run sequentially. Geoffrey stresses that this simple 2 map version can be generalized to scalable parallelism.</p>
31,X-Informatics Case Study: Health Informatics,1,Big Data and Health,,,https://iu.box.com/shared/static/r9ttvq7fq4jwdnp51dlo.pptx,i7volfOVAmY,"<p>This lesson starts with general aspects of Big Data and Health including listing subareas where Big data important. Data sizes are given in  radiology, genomics, personalized medicine, and the Quantified Self movement, with sizes and access to European Bioinformatics Institute.</p>"
31,X-Informatics Case Study: Health Informatics,2,McKinsey Report on the big-data revolution in US health care,,,https://iu.box.com/shared/static/r9ttvq7fq4jwdnp51dlo.pptx,bBoHzRjMEmY,"<p>This lesson covers 9 aspects of the McKinsey report. These are the convergence of multiple positive changes has created a tipping point for innovation; Primary data pools are at the heart of the big data revolution in healthcare; Big data is changing the paradigm: these are the value pathways; Applying early successes at scale could reduce US healthcare costs by $300 billion to $450 billion; Most new big-data applications target consumers and providers across pathways; Innovations are weighted towards influencing individual decision-making levers; Big data innovations use a range of public, acquired, and proprietary data types; Organizations implementing a big data transformation should provide the leadership required for the associated cultural transformation; Companies must develop a range of big data capabilities</p>"
31,X-Informatics Case Study: Health Informatics,3,Microsoft Report on Big Data in Health,,,https://iu.box.com/shared/static/r9ttvq7fq4jwdnp51dlo.pptx,PjffvVgj1PE,"<p>This lesson identifies data sources as Clinical Data, Pharma & Life Science Data, Patient & Consumer Data, Claims & Cost Data and Correlational Data. Three approaches are Live data feed, Advanced analytics and Social analytics.</p>"
31,X-Informatics Case Study: Health Informatics,4,EU Report on Redesigning health in Europe for 2020,,,https://iu.box.com/shared/static/r9ttvq7fq4jwdnp51dlo.pptx,9mbt_ZSs0iw,"<p>This lesson summarizes an EU Report on Redesigning health in Europe for 2020. The power of data is seen as a lever for change in My Data, My decisions; Liberate the data; Connect up everything; Revolutionize health; and Include Everyone removing the current correlation between health and wealth.</p>"
31,X-Informatics Case Study: Health Informatics,5,Clouds and Health,,,https://iu.box.com/shared/static/r9ttvq7fq4jwdnp51dlo.pptx,9Whkl_UPS5g,<p>This lesson starts with a look at a start up using clouds in Health/Medical informatics. Then we review an online presentation on Healthcare and clouds. Conforming with HIPAA act is important. Advantages of clouds include low cost and ease of anywhere access and convenience of sharing information. Security and privacy are main problem area.</p>
31,X-Informatics Case Study: Health Informatics,6,"Genomics, Proteomics and Information Visualization I",,,https://iu.box.com/shared/static/r9ttvq7fq4jwdnp51dlo.pptx,r1yENstaAUE,<p>A study of an Azure application with an Excel frontend and a cloud BLAST backend starts this lesson. This is followed by a big data analysis of personal genomics and an analysis of a typical DNA sequencing analytics pipeline. The Protein Sequence Universe is defined and used to motivate Multi dimensional Scaling MDS. Sammon's method is defined and its use illustrated by a metagenomics example. Subtleties in use of MDS include a monotonic mapping of the dissimilarity function. The application to the COG Proteomics dataset is discussed. We note that the MDS approach is related to the well known chisq method and some aspects of nonlinear minimization of chisq (Least Squares) are discussed.</p>
31,X-Informatics Case Study: Health Informatics,7,"Genomics, Proteomics and Information Visualization II",,,https://iu.box.com/shared/static/r9ttvq7fq4jwdnp51dlo.pptx,_F1Eo6bfN0w,<p>This lesson continues the discussion of the COG Protein Universe introduced in the last lesson. It is shown how Proteomics clusters are clearly seen in the Universe browser. This motivates a side remark on different clustering methods applied to metagenomics. Then we discuss the Generative Topographic Map GTM method that can be used in dimension reduction when original data is in a metric space and is in this case faster than MDS as GTM computational complexity scales like N not N squared as seen in MDS. Examples are given of GTM including an application to topic models in Information Retrieval. Indiana University has developed a deterministic annealing improvement of GTM. 3 separate clusterings are projected for visualization and show very different structure emphasizing the importance of visualizing results of data analytics. The final slide shows  an application of MDS to generate and visualize phylogenetic trees.</p>
31,X-Informatics Case Study: Health Informatics,8,"Genomics, Proteomics and Information Visualization III",,,https://iu.box.com/shared/static/r9ttvq7fq4jwdnp51dlo.pptx,R1svGGKipkc,<p>This lesson continues the discussion of the COG Protein Universe introduced in the last lesson. It is shown how Proteomics clusters are clearly seen in the Universe browser. This motivates a side remark on different clustering methods applied to metagenomics. Then we discuss the Generative Topographic Map GTM method that can be used in dimension reduction when original data is in a metric space and is in this case faster than MDS as GTM computational complexity scales like N not N squared as seen in MDS. Examples are given of GTM including an application to topic models in Information Retrieval. Indiana University has developed a deterministic annealing improvement of GTM. 3 separate clusterings are projected for visualization and show very different structure emphasizing the importance of visualizing results of data analytics. The final slide shows  an application of MDS to generate and visualize phylogenetic trees.</p>
32,X-Informatics Case Study: Sensors,1,Internet of Things,,,https://iu.box.com/shared/static/1n6v1h9xqjk4gc0nag8a.pptx,fFMvxYW6Yu0,"<p>There are predicted to be 24-50 Billion devices on the Internet by 2020; these are typically some sort of sensor defined as any source or sink of time series data. Sensors include smartphones, webcams, monitors of machine operation, barcodes, surveillance cameras, scientific sensors (especially in earth and environmental science), drones and self driving cars and more generally transportation systems. The lesson gives many examples of distributed sensors, which form a Grid that is controlled by a cloud.</p>"
32,X-Informatics Case Study: Sensors,2,Sensor Clouds,,,https://iu.box.com/shared/static/1n6v1h9xqjk4gc0nag8a.pptx,0egT1FsVGrU,<p>Geoffrey describes the architecture of a Sensor Cloud control environment and gives example of interface to an older version of it. The performance of system is measured in terms of processing latency as a function of number of involved sensors with each delivering data at 1.8 Mbps rate.</p>
32,X-Informatics Case Study: Sensors,3,Earth/Environment/Polar Science data gathered by Sensors,,,https://iu.box.com/shared/static/1n6v1h9xqjk4gc0nag8a.pptx,CS2gX7axWfI,<p>This lesson gives examples of some sensors in the Earth/Environment/Polar Science field. It starts with material from the CReSIS polar remote sensing project and then looks at the NSF Ocean Observing Initiative and NASA's MODIS or Moderate Resolution Imaging Spectroradiometer instrument on a satellite.</p>
32,X-Informatics Case Study: Sensors,4,Ubiquitous/Smart Cities,,,https://iu.box.com/shared/static/1n6v1h9xqjk4gc0nag8a.pptx,MFFIItQ3SOo,<p>For Ubiquitous/Smart cities we give two examples: Iniquitous Korea and smart electrical grids</p>
32,X-Informatics Case Study: Sensors,5,U-Korea(U=Ubiquitous),,,https://iu.box.com/shared/static/1n6v1h9xqjk4gc0nag8a.pptx,wdot23r4YKs,"<p>Korea has an interesting positioning where it is first worldwide in broadband access per capita, e-government, scientific literacy and total working hours. However it is far down in measures like quality of life and GDP. U-Korea aims to improve the latter by Pervasive computing, everywhere, anytime i.e. by spreading sensors everywhere. The example of a 'High-Tech Utopia' New Songdo is given.</p>"
32,X-Informatics Case Study: Sensors,6,Smart Grid,,,https://iu.box.com/shared/static/1n6v1h9xqjk4gc0nag8a.pptx,m3eX8act0GU,"<p>The electrical Smart Grid aims to enhance USA's aging electrical infrastructure by pervasive deployment of sensors and the integration of their measurement in a cloud or equivalent server infrastructure. A variety of new instruments include smart meters, power monitors, and measures of solar irradiance, wind speed, and temperature. One goal is autonomous local power units where good use is made of waste heat.</p>"
33,X-Informatics Case Study: Radar,1,Introduction,,,https://iu.box.com/shared/static/0r8m5fpuih5bdrcfvkic.pptx,LXOncC2AhsI,"<p>This unit motivates radar-informatics by building on previous discussions on why X-applications are growing in data size and why analytics are necessary for acquiring knowledge from large data. The unit details three mosaics of a changing Greenland ice sheet and provides a concise overview to subsequent lessons by detailing explaining how other remote sensing technologies, such as the radar, can be used to sound the polar ice sheets and what we are doing with radar images to extract knowledge to be incorporated into numerical models.</p>"
33,X-Informatics Case Study: Radar,2,Remote Sensing,,,https://iu.box.com/shared/static/0r8m5fpuih5bdrcfvkic.pptx,TTrm9rmZySQ,"<p>This explains the basics of remote sensing, the characteristics of remote sensors and remote sensing applications. Emphasis is on image acquisition and data collection in the electromagnetic spectrum.</p>"
33,X-Informatics Case Study: Radar,3,Ice Sheet Science,,,https://iu.box.com/shared/static/0r8m5fpuih5bdrcfvkic.pptx,rDpjMLguVBc,<p>This unit provides a brief understanding on why melt water at the base of the ice sheet can be detrimental and why it's important for sensors to sound the bedrock.</p>
33,X-Informatics Case Study: Radar,4,Global Climate Change,,,https://iu.box.com/shared/static/0r8m5fpuih5bdrcfvkic.pptx,f9hzzJX0qDs,"<p>This unit provides an understanding and the processes for the greenhouse effect, how warming effects the Polar Regions, and the implications of a rise in sea level.</p>"
33,X-Informatics Case Study: Radar,5,Radio Overview,,,https://iu.box.com/shared/static/0r8m5fpuih5bdrcfvkic.pptx,PuI7F-RMKCI,"<p>This unit provides an elementary introduction to radar and its importance to remote sensing, especially to acquiring information about Greenland and Antarctica.</p>"
33,X-Informatics Case Study: Radar,6,Radio Informatics,,,https://iu.box.com/shared/static/0r8m5fpuih5bdrcfvkic.pptx,q3Pwyt49syE,"<p>This unit focuses on the use of sophisticated computer vision algorithms, such as active contours and a hidden markov model to support data analysis for extracting layers, so ice sheet models can accurately forecast future changes in climate.</p>"
